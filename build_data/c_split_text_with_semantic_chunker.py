from langchain_experimental.text_splitter import SemanticChunker
from langchain_openai.embeddings import OpenAIEmbeddings
from neo4j import GraphDatabase
import streamlit as st
import logging

# Set variables for Neo4j driver
secrets = "secrets.toml"
uri = st.secrets["NEO4J_URI"]
username = st.secrets["NEO4J_USERNAME"]
password = st.secrets["NEO4J_PASSWORD"]


def read_data(tx):
    """
    Read data from Neo4j database.

    Args:
        tx: Neo4j transaction object.

    Returns:
        A list of news article body text and ids.
    """
    result = tx.run(
        "MATCH (n:News WHERE n.body IS NOT NULL) RETURN n.id, n.body, elementId(n) As elementId, n.headline_name"
    )
    return [
        (
            record["n.id"],
            record["n.body"],
            record["elementId"],
            record["n.headline_name"],
        )
        for record in result
    ]


def write_data(tx, split_id, split_text, split_source, split_url):
    """
    Write data to Neo4j database.

    Args:
        tx: Neo4j transaction object.
        split_id: The ID of the split.
        split_text: The text generated by the splitter.
        split_source: The element ID for the Neo4j 'News' node that the body text is saved to.
        split_url: The URL of the news article.
    """
    tx.run(
        """
        MATCH (n:News)
        WHERE elementId(n) = $split_source
        MERGE (n)<-[:CHILD_OF]-(ct:SplitText {split_id: $split_id, split_text: $split_text, split_source: $split_source, split_url: $split_url})
        SET n.url = $split_url
        """,
        split_id=split_id,
        split_text=split_text,
        split_source=split_source,
        split_url=split_url,
    )
    return


# Create the driver instance for reading data
driver = None
try:
    driver = GraphDatabase.driver(uri, auth=(username, password))
    driver.verify_connectivity()
    with driver.session() as session:
        results = session.execute_read(read_data)

except Exception as e:
    logging.error(f"Failed to create Neo4j driver: {e}")

# Close the driver instance
driver.close()

text_splitter = SemanticChunker(OpenAIEmbeddings())

# Loop through results
for result in results:
    id, body, elementId, headline_name = result
    texts = text_splitter.create_documents([body])

    for index, text in enumerate(texts):
        split_id = f"{id}_{index}"
        split_text = (
            str(text)
            .replace("page_content='", "")
            .replace('page_content="', "")
            .replace(r"\n", " ")
            .replace(r"\xa0", " ")
            .replace(r"\'s", "'s")
            .strip()
        )
        # Remove the last character
        split_text = split_text[:-1]
        split_source = elementId
        headline_name = headline_name.lower().replace("/", "-").replace(" ", "-")
        split_url = f"https://www.londonstockexchange.com/news-article/BRCS/{headline_name}/{id}"

        # Create the driver instance for writing data
        driver = None
        try:
            driver = GraphDatabase.driver(uri, auth=(username, password))
            driver.verify_connectivity()
            with driver.session() as session:
                session.execute_write(
                    write_data, split_id, split_text, split_source, split_url
                )

        except Exception as e:
            logging.error(f"Failed to create Neo4j driver: {e}")

        # Close the driver instance
        driver.close()

        print(split_id)
        print(split_text)
        print(split_source)
        print(split_url)
